{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd0c19c",
   "metadata": {},
   "source": [
    "# quick start\n",
    "\n",
    "In this notebook, we demonstrate how to utilize our router datasets to evaluate router performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa18808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from utils import convert_arrays_to_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a1e16",
   "metadata": {},
   "source": [
    "### The format of our router dataset is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d1c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_dataset = {\n",
    "        'easy': {\n",
    "            3: {'all_strong': {'data': None, 'model': None}, 'all_weak': {'data': None, 'model': None}, 'strong_to_weak': {'data': None, 'model': None}},\n",
    "            5: {'all_strong': {'data': None, 'model': None}, 'all_weak': {'data': None, 'model': None}, 'strong_to_weak': {'data': None, 'model': None}}\n",
    "        },\n",
    "        'hard': {\n",
    "            10: {'all_strong': {'data': None, 'model': None}, 'all_weak': {'data': None, 'model': None}, 'strong_to_weak': {'data': None, 'model': None}},\n",
    "            100: {'all_strong': {'data': None, 'model': None}, 'all_weak': {'data': None, 'model': None}, 'strong_to_weak': {'data': None, 'model': None}},\n",
    "            1000: {'all_strong': {'data': None, 'model': None}, 'all_weak': {'data': None, 'model': None}, 'strong_to_weak': {'data': None, 'model': None}}\n",
    "        },\n",
    "        'split_index':{\n",
    "            'train_indices': None, 'val_indices': None, 'test_indices': None\n",
    "        },\n",
    "        'embedding': {\n",
    "            'train_embed': None, 'val_embed': None, 'test_embed': None\n",
    "        },\n",
    "        'prompt': {\n",
    "            'train_prompt': None, 'val_prompt': None, 'test_prompt': None\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2106538a",
   "metadata": {},
   "source": [
    "### load and display the pre-built router dataset\n",
    "\n",
    "make sure that you have downloaded the ```router_dataset``` folder into the ```data``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa32b70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'easy': {3: {'all_strong': {'data': {'train_score': (1055, 3), 'val_score': (132, 3), 'test_score': (132, 3)}, 'model': (3,)}, 'all_weak': {'data': {'train_score': (1055, 3), 'val_score': (132, 3), 'test_score': (132, 3)}, 'model': (3,)}, 'strong_to_weak': {'data': {'train_score': (1055, 3), 'val_score': (132, 3), 'test_score': (132, 3)}, 'model': (3,)}}, 5: {'all_strong': {'data': {'train_score': (1055, 5), 'val_score': (132, 5), 'test_score': (132, 5)}, 'model': (5,)}, 'all_weak': {'data': {'train_score': (1055, 5), 'val_score': (132, 5), 'test_score': (132, 5)}, 'model': (5,)}, 'strong_to_weak': {'data': {'train_score': (1055, 5), 'val_score': (132, 5), 'test_score': (132, 5)}, 'model': (5,)}}}, 'hard': {10: {'all_strong': {'data': {'train_score': (1055, 10), 'val_score': (132, 10), 'test_score': (132, 10)}, 'model': (10,)}, 'all_weak': {'data': {'train_score': (1055, 10), 'val_score': (132, 10), 'test_score': (132, 10)}, 'model': (10,)}, 'strong_to_weak': {'data': {'train_score': (1055, 10), 'val_score': (132, 10), 'test_score': (132, 10)}, 'model': (10,)}}, 100: {'all_strong': {'data': {'train_score': (1055, 100), 'val_score': (132, 100), 'test_score': (132, 100)}, 'model': (100,)}, 'all_weak': {'data': {'train_score': (1055, 100), 'val_score': (132, 100), 'test_score': (132, 100)}, 'model': (100,)}, 'strong_to_weak': {'data': {'train_score': (1055, 100), 'val_score': (132, 100), 'test_score': (132, 100)}, 'model': (100,)}}, 1000: {'all_strong': {'data': {'train_score': (1055, 1000), 'val_score': (132, 1000), 'test_score': (132, 1000)}, 'model': (1000,)}, 'all_weak': {'data': {'train_score': (1055, 1000), 'val_score': (132, 1000), 'test_score': (132, 1000)}, 'model': (1000,)}, 'strong_to_weak': {'data': {'train_score': (1055, 1000), 'val_score': (132, 1000), 'test_score': (132, 1000)}, 'model': (1000,)}}}, 'split_index': {'train_indices': (1055,), 'val_indices': (132,), 'test_indices': (132,)}, 'embedding': {'train_embed': (1055, 768), 'val_embed': (132, 768), 'test_embed': (132, 768)}, 'prompt': {'train_prompt': (1055,), 'val_prompt': (132,), 'test_prompt': (132,)}}\n"
     ]
    }
   ],
   "source": [
    "# choose to_handle_datasets from below\n",
    "# ['arc', 'hellaswag', 'mmlu', 'winogrande', 'gsm8k']\n",
    "# ['ifeval', 'bbh', 'gpqa', 'musr', 'math', 'mmlu_pro']\n",
    "to_handle_dataset = 'gsm8k'\n",
    "\n",
    "# load the pre-built router dataset \n",
    "with open(f'data/router_dataset/{to_handle_dataset}_router_dataset.pkl', 'rb') as f:\n",
    "    router_dataset = pickle.load(f)\n",
    "    \n",
    "# display the pre-built router dataset \n",
    "print(convert_arrays_to_shapes(router_dataset))\n",
    "\n",
    "# You can view the router dataset here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f962eac",
   "metadata": {},
   "source": [
    "### Implement a router method (using KNN as an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf51dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_router(X_train, Y_train, X_test, Y_test, knearest):\n",
    "    \"\"\"\n",
    "    Predicts the best LLM for each test inquiry using a kNN-based correctness predictor.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: numpy array of shape (N, m), training embeddings.\n",
    "    - Y_train: numpy array of shape (N, p), binary correctness labels for each LLM.\n",
    "    - X_test: numpy array of shape (N', m), test embeddings.\n",
    "    - Y_test: numpy array of shape (N', p), binary correctness labels for each LLM.\n",
    "    - knearest: int, number of nearest neighbors to use (default is 5).\n",
    "    \n",
    "    Returns:\n",
    "    - mu: the overall performance of the LLMs selected by router on the given benchmark.\n",
    "    - vb: mu/bsm, bsm denotes best performance of a single model in the candidate set\n",
    "    - ep: classification bias (measure the diversity of the classifierâ€™s prediction distribution)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the nearest neighbors model using cosine distance.\n",
    "    nn_model = NearestNeighbors(n_neighbors=knearest, metric='cosine')\n",
    "    nn_model.fit(X_train)\n",
    "    \n",
    "    # For each test inquiry, find the indices of its k nearest training inquiries.\n",
    "    distances, indices = nn_model.kneighbors(X_test)\n",
    "    \n",
    "    # Number of test inquiries and number of available LLMs.\n",
    "    num_test = X_test.shape[0]\n",
    "    num_llms = Y_train.shape[1]\n",
    "    \n",
    "    # Initialize an array to store the predicted correctness probability for each LLM.\n",
    "    predicted_probs = np.zeros((num_test, num_llms))\n",
    "    \n",
    "    # For each test inquiry, average the correctness labels of its k nearest neighbors.\n",
    "    for i in range(num_test):\n",
    "        neighbor_indices = indices[i]  # indices of the k nearest neighbors for test inquiry i.\n",
    "        # Average the correctness labels across these neighbors for each LLM.\n",
    "        predicted_probs[i] = np.mean(Y_train[neighbor_indices], axis=0)\n",
    "    \n",
    "    # For each test inquiry, select the LLM with the highest predicted correctness probability.\n",
    "    predicted_llm_indices = np.argmax(predicted_probs, axis=1)\n",
    "    \n",
    "    \n",
    "    # calculate metrics\n",
    "    mu = np.mean(Y_test[np.arange(Y_test.shape[0]), predicted_llm_indices])\n",
    "    vb = mu / np.max(np.mean(Y_test, axis=0))\n",
    "    \n",
    "    # softmax\n",
    "    predicted_probs = np.exp(predicted_probs - np.max(predicted_probs, axis=1, keepdims=True)) / np.sum(np.exp(predicted_probs - np.max(predicted_probs, axis=1, keepdims=True)), axis=1, keepdims=True)\n",
    "    # calculate classification bias Ep\n",
    "    terms = np.where(predicted_probs > 1e-10, predicted_probs * np.log2(predicted_probs), 0)\n",
    "    ep = -np.sum(terms) / predicted_probs.shape[0] \n",
    "   \n",
    "    return mu, vb, ep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607f3db",
   "metadata": {},
   "source": [
    "### train and test the router\n",
    "\n",
    "Use the data from the router dataset to train and test the router, and output the performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e453c93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsm8k      knn        num=5          all_strong     \n",
      "mu: 0.8258,  Vr: 0.8976,  Vb: 0.9397,  Ep: 2.3123\n",
      "\n",
      "gsm8k      knn        num=5          all_weak       \n",
      "mu: 0.4545,  Vr: 0.4941,  Vb: 1.1321,  Ep: 2.3025\n",
      "\n",
      "gsm8k      knn        num=5          strong_to_weak \n",
      "mu: 0.8485,  Vr: 0.9223,  Vb: 0.9333,  Ep: 2.2711\n",
      "\n",
      "gsm8k      knn        num=5          avg_metrics    \n",
      "mu: 0.7096,  Vr: 0.7713,  Vb: 1.0017,  Ep: 2.2953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The difficulty level and num_candidates settings of the router dataset\n",
    "difficulty = 'easy'  # 'easy' / 'hard'\n",
    "\n",
    "# Under the \"easy\" setting, you can choose from [3, 5]\n",
    "# under the \"hard\" setting, you can choose from [10, 100, 1000].\n",
    "num_candidates = 5   # 3 / 5 / 10 / 100 / 1000\n",
    "\n",
    "# The parameter k of the KNN router, default = 5\n",
    "knearest = 5\n",
    "\n",
    "\n",
    "# For each benchmark, we select a representative LLM with strong performance as the reference, such as GPT-4\n",
    "acc_ref_dict = {'arc': 0.852, 'hellaswag': 0.953, 'mmlu': 0.864, 'harness_truthfulqa_mc_0': 0.669, 'winogrande': 0.875, 'gsm8k': 0.92,\n",
    "           'ifeval': 0.7689, 'bbh': 0.8303, 'gpqa': 0.397, 'math': 0.4, 'musr': 0.699, 'mmlu_pro': 0.637}\n",
    "\n",
    "# get acc of the ref LLM\n",
    "acc_ref = acc_ref_dict[to_handle_dataset]\n",
    "\n",
    "mu = []\n",
    "vr = []\n",
    "vb = []\n",
    "ep = []\n",
    "for config in ['all_strong', 'all_weak', 'strong_to_weak']:\n",
    "    train_embed = router_dataset['embedding']['train_embed']\n",
    "    test_embed = router_dataset['embedding']['test_embed']\n",
    "    train_score = router_dataset[difficulty][num_candidates][config]['data']['train_score']\n",
    "    test_score = router_dataset[difficulty][num_candidates][config]['data']['test_score']\n",
    "    \n",
    "    print(f\"{to_handle_dataset:<10}\", f\"{'knn':<10}\", f\"num={num_candidates:<10}\", f\"{config:<15}\")\n",
    "    mu1, vb1, ep1 = knn_router(train_embed, train_score, test_embed, test_score, knearest)\n",
    "    vr1 = mu1 / acc_ref\n",
    "    print(f\"mu: {mu1:.4f},  Vr: {vr1:.4f},  Vb: {vb1:.4f},  Ep: {ep1:.4f}\")\n",
    "    print()\n",
    "    mu.append(mu1)\n",
    "    vr.append(vr1)\n",
    "    vb.append(vb1)\n",
    "    ep.append(ep1)\n",
    "\n",
    "\n",
    "print(f\"{to_handle_dataset:<10}\", f\"{'knn':<10}\", f\"num={num_candidates:<10}\", f\"{'avg_metrics':<15}\")\n",
    "print(f\"mu: {np.mean(mu):.4f},  Vr: {np.mean(vr):.4f},  Vb: {np.mean(vb):.4f},  Ep: {np.mean(ep):.4f}\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab61e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
